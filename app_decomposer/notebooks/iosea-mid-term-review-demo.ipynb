{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'iosea-venv (Python 3.8.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from utils_demo import *\n",
    "from loguru import logger\n",
    "from unittest.mock import patch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"recommendation_system_diagram.png\"\n",
    "     alt=\"Rec System\"\n",
    "     style=\"width: 55vw; float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching IOI job and decomposing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![App Decomposer Picture](app_decomposer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_detected_phases(jobid=3911, merge=False, show_phases=False, width=1200, height=600)\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "logger.remove()\n",
    "def decompose_ioi_job(jobid):\n",
    "    with patch.object(ComplexDecomposer, 'get_job_timeseries') as mock_get_timeseries:\n",
    "        with patch.object(Configuration, 'get_kc_token') as mock_get_kc_token:\n",
    "            mock_get_timeseries.return_value = get_job_timeseries_from_file(job_id=jobid)\n",
    "            mock_get_kc_token.return_value = 'token'\n",
    "            # init the job decomposer\n",
    "            cd = ComplexDecomposer()\n",
    "            return cd\n",
    "        \n",
    "# Launch decomposition on the signal\n",
    "cd = decompose_ioi_job(jobid=3911)\n",
    "compute, reads, read_bw, writes, write_bw = cd.get_job_representation()\n",
    "# This is the app encoding representation for Execution Simulator\n",
    "print(f\"compute={compute}, reads={reads}, read_bw={read_bw}\")\n",
    "print(f\"compute={compute}, writes={writes}, write_bw={write_bw}\")\n",
    "# Normalize signals to seconds and MB\n",
    "timestamps = (cd.timestamps.flatten() - cd.timestamps.flatten()[0])/5\n",
    "original_read =  cd.read_signal.flatten()/1e6\n",
    "original_write = cd.write_signal.flatten()/1e6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we obtain a representation of the job that \"removes\" the performance of the storage tier:\n",
    "- Events (timestamps) = [0, 1, 7, 11, 12, 18, 20, 23, 35, 48, 59, 65, 66]\n",
    "- Reads (volumes in GB) = [0.0, 23.39, 31.69, 0.0, 28.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "- Writes (volumes in GB) = [0.0, 0.0, 0.0, 0.0, 0.0, 2.07, 9.79, 3.51, 4.32, 21.23, 10.67, 4.58, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(compute)\n",
    "print(list(map(lambda x: round(x/1e9, 2), reads)))\n",
    "print(list(map(lambda x: round(x/1e9, 2), writes)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signal reconstruction from the representation:\n",
    "- we reuse measured bandwidths for both read and write signal\n",
    "- we feed the Simulator with this data, instead of providing a Storage Performance Model: bw = f(IO_size, IO_pattern, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply same BW as measured by IOI\n",
    "read_bw = list(map(lambda x: x/1e6, read_bw))\n",
    "write_bw = list(map(lambda x: x/1e6, write_bw))\n",
    "io_bw = list(map(lambda x, y: x + y, read_bw, write_bw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding App Simulator with the representation\n",
    "We use the representation as an input for Execution Simulator\n",
    "![App Decomposer Picture](cluster_simulator.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_time, sim_read_bw, sim_write_bw = simulate_app(compute, reads, writes, io_bw, app_name=\"3911\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Simulation versus Origial (IOI) signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = display_original_sim_signals((sim_time, sim_read_bw, sim_write_bw),\n",
    "                                   (timestamps, original_read, original_write),\n",
    "                                   width=1400, height=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Until now, we just replayed the representation into the simulator.\n",
    "- But the aim of the Simulator is to predict the expected execution time for a different storage tier.\n",
    "- The Simualtor will accept later the performance model for a tier bw = f(IO_size, IO_pattern,...)\n",
    "- For now we will __mock__ the model with a hardcoded io_bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We simulate that the app data will be placed in a storage backend having the following perfs\n",
    "tier_mean_read_bw = 5e3\n",
    "tier_mean_write_bw = 1e3\n",
    "io_bw = list(map(lambda x, y: tier_mean_read_bw if x else 0 + tier_mean_write_bw if y else 0, read_bw, write_bw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And rerun the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = display_original_sim_signals(simulate_app(compute, reads, writes, io_bw, app_name=\"3911\"),\n",
    "                                   (timestamps, original_read, original_write),\n",
    "                                   width=1400, height=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected duration of the application is 129x5s = 645 seconds with this storage instead of 97x5s = 485 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion and further improvements:\n",
    "- fix bugs on the AppDecompser 0.1\n",
    "- update simulator to accept phases having both read and write I/O\n",
    "- build a Performance Model with bandwidths measured directly from the storage tier\n",
    "- progressing toward simulating workflows having many jobs in parallel (already supported in App Simulator) and recommending placement for each step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('iosea-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c87beb4c7de1fcbf6155f8da331fc04a584374d4c389d75c2ece6a4f03553c96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
