{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home_nfs/mimounis/iosea-wp3-recommandation-system/performance_data/performance_data/dataset/performance_model_dataset.csv\n",
      "/home_nfs/mimounis/iosea-wp3-recommandation-system/performance_data/performance_data/dataset/performance_model_dataset_complete.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import unittest\n",
    "import requests\n",
    "import urllib3\n",
    "from utils_demo import *\n",
    "from loguru import logger\n",
    "from unittest.mock import patch\n",
    "from pprint import pprint\n",
    "from os.path import dirname, abspath\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from performance_data.performance_data import PhaseData, DataTable\n",
    "from performance_data import DATASET_FILE\n",
    "from app_decomposer import DEFAULT_CONFIGURATION, KIWI_CONFIG, CURRENT_DIR, API_DICT_TS, IOI_SAMPLING_PERIOD, DATASET_SOURCE\n",
    "from app_decomposer.api_connector import request_delegator\n",
    "from app_decomposer.config_parser import Configuration\n",
    "from app_decomposer.api_connector import TimeSeries\n",
    "print(DATASET_SOURCE)\n",
    "print(DATASET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    job_id     volume   mode IOpattern    IOsize  nodes     ioi_bw     lfs_bw  \\\n",
      "0     6873    1.64 KB   read      uncl   328.4 B      1    164.2 B   491.4 MB   \n",
      "1     6873    9.62 GB   read      rand   1.05 MB      1    1.92 GB   596.3 MB   \n",
      "2     6873   48.12 GB   read      rand   5.24 MB      1    4.81 GB  634.12 MB   \n",
      "3     6873   96.24 GB   read      rand  10.48 MB      1    6.42 GB  730.83 MB   \n",
      "4     6873   10.49 GB  write      rand   1.05 MB      1  524.29 MB  214.55 MB   \n",
      "5     6873   52.43 GB  write      rand   5.24 MB      1  582.54 MB  260.76 MB   \n",
      "6     6873  104.86 GB  write      rand  10.49 MB      1   676.5 MB  265.19 MB   \n",
      "7     6873         0B   read      uncl        0B      1         0B         0B   \n",
      "8     6873    1.64 KB   read      uncl   328.4 B      1    164.2 B  492.13 MB   \n",
      "9     6873    9.62 GB   read      rand   1.05 MB      1    1.92 GB  593.82 MB   \n",
      "10    6873   48.12 GB   read      rand   5.24 MB      1    4.81 GB   640.2 MB   \n",
      "11    6873   96.24 GB   read      rand  10.48 MB      1    6.42 GB  727.28 MB   \n",
      "12    6873   10.49 GB  write      rand   1.05 MB      1  524.29 MB  223.61 MB   \n",
      "13    6873   52.43 GB  write      rand   5.24 MB      1  582.54 MB   245.1 MB   \n",
      "14    6873  104.86 GB  write      rand  10.49 MB      1   676.5 MB  270.25 MB   \n",
      "15    6873         0B   read      uncl        0B      1         0B         0B   \n",
      "\n",
      "       sbb_bw  \n",
      "0    11.34 MB  \n",
      "1   939.85 MB  \n",
      "2   982.32 MB  \n",
      "3     1.03 GB  \n",
      "4   221.73 MB  \n",
      "5   272.55 MB  \n",
      "6   266.34 MB  \n",
      "7          0B  \n",
      "8    11.18 MB  \n",
      "9   959.69 MB  \n",
      "10  996.02 MB  \n",
      "11    1.23 GB  \n",
      "12  259.61 MB  \n",
      "13  282.81 MB  \n",
      "14  284.94 MB  \n",
      "15         0B  \n"
     ]
    }
   ],
   "source": [
    "# checking dataset values\n",
    "print_readable_values(\"/home_nfs/mimounis/iosea-wp3-recommandation-system/performance_data/performance_data/dataset/performance_model_dataset_complete.csv\", [\"volume\", \"IOsize\", \"ioi_bw\", \"lfs_bw\",\"sbb_bw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    job_id     volume   mode IOpattern    IOsize  nodes     ioi_bw     lfs_bw  \\\n",
      "0     6873    1.64 KB   read      uncl   328.4 B      1    164.2 B     4.0 KB   \n",
      "1     6873    9.62 GB   read      rand   1.05 MB      1    1.92 GB  658.49 MB   \n",
      "2     6873   48.12 GB   read      rand   5.24 MB      1    4.81 GB     3.1 GB   \n",
      "3     6873   96.24 GB   read      rand  10.48 MB      1    6.42 GB    7.15 GB   \n",
      "4     6873   10.49 GB  write      rand   1.05 MB      1  524.29 MB  230.18 MB   \n",
      "5     6873   52.43 GB  write      rand   5.24 MB      1  582.54 MB  322.43 MB   \n",
      "6     6873  104.86 GB  write      rand  10.49 MB      1   676.5 MB  330.36 MB   \n",
      "7     6873         0B   read      uncl        0B      1         0B         0B   \n",
      "8     6873    1.64 KB   read      uncl   328.4 B      1    164.2 B     8.6 KB   \n",
      "9     6873    9.62 GB   read      rand   1.05 MB      1    1.92 GB  664.72 MB   \n",
      "10    6873   48.12 GB   read      rand   5.24 MB      1    4.81 GB    3.14 GB   \n",
      "11    6873   96.24 GB   read      rand  10.48 MB      1    6.42 GB    7.18 GB   \n",
      "12    6873   10.49 GB  write      rand   1.05 MB      1  524.29 MB  236.36 MB   \n",
      "13    6873   52.43 GB  write      rand   5.24 MB      1  582.54 MB  321.34 MB   \n",
      "14    6873  104.86 GB  write      rand  10.49 MB      1   676.5 MB  330.37 MB   \n",
      "15    6873         0B   read      uncl        0B      1         0B         0B   \n",
      "\n",
      "       sbb_bw  \n",
      "0     5.13 KB  \n",
      "1   477.56 MB  \n",
      "2     5.23 GB  \n",
      "3    16.87 GB  \n",
      "4   285.61 MB  \n",
      "5   344.79 MB  \n",
      "6   356.27 MB  \n",
      "7          0B  \n",
      "8     4.95 KB  \n",
      "9     1.64 GB  \n",
      "10    7.98 GB  \n",
      "11   18.13 GB  \n",
      "12  287.65 MB  \n",
      "13  346.86 MB  \n",
      "14   355.3 MB  \n",
      "15         0B  \n"
     ]
    }
   ],
   "source": [
    "# checking dataset values\n",
    "print_readable_values(\"/home_nfs/mimounis/iosea-wp3-recommandation-system/performance_data/performance_data/dataset/performance_model_dataset_complete_2.csv\", [\"volume\", \"IOsize\", \"ioi_bw\", \"lfs_bw\",\"sbb_bw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Connect directly to kiwi0\n",
    "logger.remove()\n",
    "ioi_config = Configuration(path=KIWI_CONFIG)\n",
    "job_id = 6873 #5168\n",
    "cd = ComplexDecomposer(job_id=job_id, v0_threshold=1e-8, config=ioi_config)\n",
    "# Launch decomposition on the signal\n",
    "representation = cd.get_job_representation(merge_clusters=True)\n",
    "pprint(representation)\n",
    "# This is the app encoding representation for Execution Simulator\n",
    "pprint(f\"compute={representation['events']}, reads={representation['read_volumes']}\" \n",
    "      f\"read_bw={representation['read_bw']}, writes={representation['write_volumes']}\"\n",
    "      f\"write_bw={representation['write_bw']}, read_pattern={representation['read_pattern']}\")\n",
    "# Normalize signals to seconds and MB\n",
    "timestamps = (cd.timestamps - cd.timestamps[0])/5\n",
    "original_read = cd.read_signal/1e6\n",
    "original_write = cd.write_signal/1e6\n",
    "\n",
    "fig = plot_detected_phases(jobid=job_id, merge=True, show_phases=True, \n",
    "                           ts=(timestamps, original_read, original_write),\n",
    "                           width=800, height=600)\n",
    "fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract phases table and features\n",
    "phases_features = cd.get_phases_features(representation,\n",
    "                                         job_id = job_id,\n",
    "                                         update_csv=True)\n",
    "\n",
    "# display the csv table\n",
    "# DATASET_SOURCE\n",
    "print(pd.read_csv(DATASET_SOURCE, index_col=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed three columns of the CSV table by launching tiers perf measurements\n",
    "# with nfw_bw | lfs_bw | sbb_bw\n",
    "print(DATASET_FILE)\n",
    "#targets = dict(lfs=\"/fsiof/mimounis/tmp\", nfs=\"/scratch/mimounis/tmp\")\n",
    "targets = dict(lfs=\"/fsiof/mimounis/tmp\")\n",
    "dt = DataTable(targets, accelerator=True)\n",
    "df = dt.get_performance_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the csv table\n",
    "# DATASET_SOURCE\n",
    "print(pd.read_csv(DATASET_FILE, index_col=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply same BW as measured by IOI (from representation)\n",
    "read_bw = list(map(lambda x: x/1e6, representation['read_bw']))\n",
    "write_bw = list(map(lambda x: x/1e6, representation['write_bw']))\n",
    "ioi_bw = list(map(lambda x, y: (x + y), read_bw, write_bw))\n",
    "print(ioi_bw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the BW predicted if the app run on some tiers // no model, just indexed tabular\n",
    "df = pd.read_csv(DATASET_FILE, index_col=False)\n",
    "df = pd.read_csv(\"/home_nfs/mimounis/iosea-wp3-recommandation-system/performance_data/performance_data/dataset/performance_model_dataset_complete_2.csv\", index_col=False)\n",
    "job_df = df[df[\"job_id\"] == job_id]\n",
    "perf = {}\n",
    "for tier_bw in [\"lfs_bw\", \"sbb_bw\"]:\n",
    "    rough_bw = list(job_df[[tier_bw]].to_numpy().flatten())\n",
    "    # perf adjusted to IOI\n",
    "    perf[tier_bw] = list(map(lambda x: x*5/1e6, rough_bw))       \n",
    "perf[\"ioi_bw\"] = list(map(lambda x: x*5/1e6, job_df[[\"ioi_bw\"]].to_numpy().flatten()))\n",
    "print(perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncorrelate reads and writes to avoid simulator crash (not accepting mixed R/W)\n",
    "events = representation['events']\n",
    "reads = list(map(lambda x, y: x if x > y else 0, representation['read_volumes'], representation[\"write_volumes\"]))\n",
    "writes = list(map(lambda x, y: x if x > y else 0, representation['write_volumes'], representation[\"read_volumes\"]))\n",
    "print(events)\n",
    "print(reads)\n",
    "print(writes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare simulated on SBB\n",
    "sim_time, sim_read_bw, sim_write_bw = simulate_app(events, reads, writes,\n",
    "                                                   perf[\"sbb_bw\"], app_name=\"job#6873\")\n",
    "print(sim_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ground truth = experimental job of the same app running the the specified tier for verification.\n",
    "cd = ComplexDecomposer(job_id=6871, v0_threshold=1e-8, config=ioi_config)\n",
    "timestamps = (cd.timestamps - cd.timestamps[0])/5000\n",
    "original_read = cd.read_signal/1e6\n",
    "original_write = cd.write_signal/1e6\n",
    "# 5168-5175: nfs\n",
    "# 5182-5184: fs1\n",
    "# 5192-5194: sbb\n",
    "fig = display_original_sim_signals((sim_time, sim_read_bw, sim_write_bw),\n",
    "                                   (timestamps, original_read, original_write),\n",
    "                                   str_org=\"Experimental lfs sbb\",\n",
    "                                   str_sim=\"Predicted\",\n",
    "                                   width=800, height=600)\n",
    "fig.show()\n",
    "# timestamps, experimental_read, experimental_write = get_job_timeseries_from_file_as_array(job_id=5168)\n",
    "# timestamps = (timestamps - timestamps[0])/5\n",
    "# experimental_read = experimental_read/1e6\n",
    "# experimental_write = experimental_write/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_time, sim_read_bw, sim_write_bw = simulate_app(representation['events'],\n",
    "                                                   representation['read_volumes'],\n",
    "                                                   representation['write_volumes'], \n",
    "                                                   perf[\"ioi_bw\"], app_name=\"job#6873\")\n",
    "\n",
    "\n",
    "fig = display_original_sim_signals((sim_time, sim_read_bw, sim_write_bw),\n",
    "                                   (timestamps, experimental_read, experimental_write),\n",
    "                                   str_org=\"Experimental (ioi_bw)\",\n",
    "                                   str_sim=\"Predicted\",\n",
    "                                   width=1000, height=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"coco\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67356b80ae16e0e40687386dbd074ace3ba90441f54bfe58917536db46d8a36b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
