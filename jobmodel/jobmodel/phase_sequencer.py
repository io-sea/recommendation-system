#!/usr/bin/env python
""" This module proposes classes to generate for a given job the corresponding sequence of operating
phases from data metrics stored in a database
"""

from __future__ import division, absolute_import, generators, print_function, unicode_literals,\
                       with_statement, nested_scopes # ensure python2.x compatibility

__copyright__ = """
Copyright (C) 2017 Bull S. A. S. - All rights reserved
Bull, Rue Jean Jaures, B.P.68, 78340, Les Clayes-sous-Bois, France
This is not Free or Open Source software.
Please contact Bull S. A. S. for details about its license.
"""

import collections
import operator
import numpy as np
import pandas as pd
from ioanalyticstools.normalizers import meanmax_normalization
from jobmodel import mongodb_extractor

class PhaseDetector:
    """ Detect all the timeframes that correspond to a specific running phase
    state (e.g. start, checkpoint, IOinactive, ...)
    """
    def __init__(self, metrics_data):
        """ Load the model used to detect phase of timeframes

        Args:
            metrics_data: metrics using for phase detector
        """
        self.m_data = metrics_data

    def detect(self, criteria_function):
        """ Apply a selection rule (criteria_function) regarding metrics in dict_db
        and return the corresponding boolean array

        Args:
            state_phase: criteria function using for phase detector
        """
        state_phase = criteria_function(self.m_data)
        return state_phase


class PhaseSequencer:
    """ Build the sequence of running phases of a job using a classifier model.
    The model (stored in a separate file) describes the criteria rules used by
    PhaseDetector.detect() and the rule priorities.
    """

    def __init__(self, classifier):
        """ Load the model used to classify the timeframes

        Args:
            classifier: classification model description (see model.py)
        """
        self.model = classifier
        self.mdb = None
        self.data = None

    def set_data(self, dict_db, jobid):
        """ Set the database and select data required

        Args:
            dict_db (dict): dictionnary of the selected database
            jobid (int): id of the selected job
        """
        self.mdb = mongodb_extractor.MetricsDataBuilder(dict_db, jobid)
        self.data = self.mdb.select_data_from_db(self.model['requirements'])

    def get_phase_sequence(self, order, sym_list):
        """ Generate the sequence of phases depicted as symbols associated to models
        criteria (see classifier type)

        Args:
            order (list): list of priority order to apply the rules
            sym_list (list): list of symbols used to represent each phases
        """
        ph_detector = PhaseDetector(self.data)
        first = True
        for phase_type, symbol in zip(order, sym_list):
            rule = self.model[phase_type]
            sym_loc = ph_detector.detect(rule)

            if first:
                seq = np.zeros_like(sym_loc).astype(str)
                first = False
            seq[sym_loc] = symbol
        return ''.join(seq)

    def get_splited_phase_sequences(self):
        """ Generate the sequence of phases as array of bool associated to models criteria\
        (see classifier type)

        Returns:
            phase_sequences (list): list of sequences after splitted
        """
        ph_detector = PhaseDetector(self.data)
        phase_sequences = {}

        for phase_type, rule in self.model.items():
            if callable(rule):
                phase_sequences[phase_type] = ph_detector.detect(rule)

        return phase_sequences


class PhaseCorrector:
    """Verify if the sequence of phases generated by the phaseSequencer could be updated because of
    neighbour timeframe similarities.
    The similarities are determined regarding the euclidian distance between the features
    associated to the timeframes. If an improvement is detected, a new sequence with the
    detected corrections is generated
    """
    def __init__(self, ph_seq, threshold=0.95, window=5):
        """Initiate an object for the PhaseCorrector class

        Args:
            self.threshold (float): threshold of similarites
            self.window (int): size of the window to detect timeframe similarities
            self.ph_seq (numpy array): the sequence of sympols to be verified
            corr_seq (numpy array): the new sequence integrating the corrections
        """
        self.threshold = threshold
        self.window = window
        self.ph_seq = ph_seq
        self.corr_seq = [''] * len(self.ph_seq)

    def tf_correction(self, f_mat, idx_tf, value_tf):
        """Compute a best correction candidate for the processed timeframe.

        Args:
            f_mat (numpy array): the collection of features of all timeframe of a job
            idx_tf (int): index of the processed timeframe
            value_tf (char): the current symbol of the processed timeframe

        Returns:
            corr (numpy array): the new sequence integrating the corrections
            score (list): similarity scores between current symbol and its neighbours
        """
        tf_tested = f_mat[idx_tf, :]
        start = min(max(idx_tf-self.window, 0), f_mat.shape[0]-(2*self.window+1))
        end = max(idx_tf+self.window+1, 2*self.window+1)
        score = get_local_euclidian_score(tf_tested, f_mat[start : end])

        window_phases = self.ph_seq[start : end]
        close_phases = [window_phases[i] for i in range(len(score)) \
                        if score[i] > self.threshold]
        corrrection_candidate = max(collections.Counter(close_phases).items(), \
                                key=operator.itemgetter(1))[0]

        if (value_tf == 'E' and 'E' in set(self.corr_seq[idx_tf-self.window:idx_tf])) \
        or (value_tf == 'S' and 'S' in set(self.ph_seq[idx_tf:idx_tf+self.window+1])) \
        or (corrrection_candidate == 'I'):
            corr = value_tf
        else:
            corr = corrrection_candidate

        return corr, score

    def seq_verif(self, f_mat, verbosity=1):
        """Verify if the phase state associated to a timeframe could be updated because of
        neighbour timeframe similarities and generate a new sequence with the detected corrections

        Args:
            f_mat (numpy array): the collection of features of all timeframe of a job

        Returns:
            self.corr_seq (numpy array): the new sequence integrating the corrections
            n_modif (int): a counter of the number of updated phases states
        """
        self.corr_seq = [''] * len(self.ph_seq)
        n_modif = 0

        if len(self.ph_seq) != f_mat.shape[0]:
            raise ValueError("Impossible to perform phase correction on this Sequence : the\
            Sequence and Feature matrix must have the same length")

        for idx_tf, value_tf in enumerate(self.ph_seq):
            if value_tf == 'I':
                self.corr_seq[idx_tf] = value_tf
            else:
                self.corr_seq[idx_tf], score = self.tf_correction(f_mat, idx_tf, value_tf)

                if self.ph_seq[idx_tf] != self.corr_seq[idx_tf]:
                    if verbosity:
                        print("\nCorrection of Phases :")
                        print("----------------------")
                        print("Index ", idx_tf, " : ", self.ph_seq[idx_tf],
                              " --> ", self.corr_seq[idx_tf], score)
                    n_modif += 1
        return ''.join(self.corr_seq), n_modif


def get_local_euclidian_score(tf_test, feature_mat):
    """Compute the euclidian distance between the tested Timeframe and all the other ones in
    featureMat. Then convert the distance in a score of similarity.

    Args:
        tf_test (numpy array): the selected normalized feature of the tested timeframe
        feature_mat (numpy array): matrix storing several timeframes features information

    Returns:
        score (list): an array with the score similarity (between 0 and 1) between the tested TF and
        the other ones in featureMat
    """
    euclidian_distance = [sum((tf - tf_test)**2)/len(tf) for tf in feature_mat]
    score = [(1 - i) for i in euclidian_distance]
    return score


def select_data_phase_correction(metrics_data):
    """Collect the selected metrics from the database dictionnary, and store them in a numpy array
    matrix

    Args:
        metrics_data (object): instance of MetricsDataBuilder (see mongodb_extractor.py)

    Returns:
        data (pandas.dataframe): dataframe of the selected data
    """
    selected_metrics = {'IODurationsGw': ['read', 'write'],
                        'FileIOSummaryGw':["bytesRead",
                                           "bytesWritten",
                                           "filesCreated",
                                           "filesDeleted",
                                           "filesRO",
                                           "filesRW",
                                           "filesWO"]}

    data = metrics_data.select_data_from_db(selected_metrics)

    r_dict = data[['read', 'write']]
    data["nIoRead"] = pd.Series([sum(i.values()) for i in r_dict.read], index=r_dict.read.index)
    data["nIoWrite"] = pd.Series([sum(i.values()) for i in r_dict.write], index=r_dict.read.index)
    data = data.drop(['read', 'write'], axis=1)

    return data


def build_matrix(metrics_data):
    """ Build the matrix of selected features

    Args:
        metrics_data (object): instance of MetricsDataBuilder (see mongodb_extractor.py)
    """
    feature_matrix = select_data_phase_correction(metrics_data)
    return meanmax_normalization(np.array(feature_matrix))


def get_metric_sequences(list_mdb, metrics):
    """ Extract the sequences of a set of metrics for a set of jobs

    Args:
        list_mdb (dict): list of instances of MetricsDataBuilder (see mongodb_extractor.py),
        one by job (as key)
        metrics (dict): dictionary of the database documents corresponding to the metric,
        with collection as key
    Returns:
        sequences (dict): a dictionary of lists of all the sequences (numpy array) of the selected
        metrics for all considered jobs
    """
    sequences = {}
    for collec, group_doc in metrics.items():
        for doc in group_doc:
            jobid_ref = list(list_mdb.keys())[0]
            elem_ref = list_mdb[jobid_ref].dict_db[collec][doc].values[0]
            if isinstance(elem_ref, dict):
                histo_ref, _ = list_mdb[jobid_ref].get_full_histogram(collec, doc)
                for histo_bin in range(len(histo_ref.values[0])):
                    metric_name = '-'.join([collec, doc, 'range'+str(histo_bin)])
                    print('Extract jobs sequences from {}'.format(metric_name))
                    sequences[metric_name] = []
                    for jobid, mdb in list_mdb.items():
                        histo, _ = mdb.get_full_histogram(collec, doc)
                        data = histo.values[:, histo_bin]
                        sequences[metric_name].append(data)
            else:
                metric_name = '-'.join([collec, doc])
                print('Extract jobs sequences from {}'.format(metric_name))
                sequences[metric_name] = []
                for jobid, mdb in list_mdb.items():
                    data = mdb.dict_db[collec].loc[jobid][doc].values
                    sequences[metric_name].append(data)
    return sequences
