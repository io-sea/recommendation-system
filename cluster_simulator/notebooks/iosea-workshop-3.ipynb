{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a770398\\AppData\\Local\\Continuum\\anaconda3\\envs\\iosea-venv\\lib\\site-packages\\cma\\s.py:13: UserWarning:\n",
      "\n",
      "Could not import matplotlib.pyplot, therefore ``cma.plot()`` etc. is not available\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "# imports\n",
    "import simpy\n",
    "from loguru import logger\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cluster_simulator.utils import convex_hull\n",
    "from cluster_simulator.cluster import Cluster, Tier, EphemeralTier, bandwidth_share_model, compute_share_model, get_tier, convert_size\n",
    "from cluster_simulator.phase import DelayPhase, ComputePhase, IOPhase\n",
    "from cluster_simulator.application import Application\n",
    "from cluster_simulator.analytics import display_run\n",
    "from cluster_simulator.ephemeral_placement import ClusterBlackBox\n",
    "from cluster_simulator.placement_optimizer import PlacementOptimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the Cluster:\n",
    "- with one tier level (HDD)\n",
    "- with an ephemeral tier:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim env an data\n",
    "env = simpy.Environment()\n",
    "data = simpy.Store(env)\n",
    "# tier perfs\n",
    "nvram_bandwidth = {'read':  {'seq': 800, 'rand': 800},\n",
    "                        'write': {'seq': 400, 'rand': 400}}\n",
    "ssd_bandwidth = {'read':  {'seq': 200, 'rand': 200},\n",
    "                    'write': {'seq': 100, 'rand': 100}}\n",
    "hdd_bandwidth = {'read':  {'seq': 80, 'rand': 80},\n",
    "                    'write': {'seq': 40, 'rand': 40}}\n",
    "\n",
    "# registering Tiers\n",
    "hdd_tier = Tier(env, 'HDD', bandwidth=hdd_bandwidth, capacity=1e12)\n",
    "ssd_tier = Tier(env, 'SSD', bandwidth=ssd_bandwidth, capacity=200e9)\n",
    "nvram_tier = Tier(env, 'NVRAM', bandwidth=nvram_bandwidth,\n",
    "                        capacity=10e9)\n",
    "# registering Ephemeral Tier\n",
    "bb = EphemeralTier(env, name=\"BB\", persistent_tier=hdd_tier,\n",
    "                        bandwidth=nvram_bandwidth, capacity=10e9)\n",
    "\n",
    "# Define the cluster with 1 persistent and 1 ephemeral\n",
    "cluster = Cluster(env, tiers=[hdd_tier], ephemeral_tier=bb)\n",
    "\n",
    "# define app\n",
    "read = [1e9, 0]\n",
    "compute = [0,  10]\n",
    "write = [0, 5e9]\n",
    "app1 = Application(env, compute=compute, read=read, write=write, data=data)\n",
    "\n",
    "# placement\n",
    "placement = [0, 0]\n",
    "use_bb = [False, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behavior for no SBB app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = PlacementOptimizer(env, data, cluster, [app1])\n",
    "fig = p1.display_placement(placement + [0, 0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selective SBB per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = PlacementOptimizer(env, data, cluster, [app1])\n",
    "fig = p1.display_placement(placement + [0, 1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about prefetch ? (buffering read datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "# sim env an data\n",
    "data = simpy.Store(env)\n",
    "logger.remove()\n",
    "# Simple app: read 1GB -> compute 10s -> write 5GB\n",
    "compute = [0,  10]\n",
    "read = [1e9, 0]\n",
    "write = [0, 5e9]\n",
    "placement = [0, 0]\n",
    "use_bb = [True, False]\n",
    "app = Application(env, compute=compute, read=read, write=write, data=data)\n",
    "env.process(app.run(cluster, placement=placement, use_bb=use_bb))\n",
    "env.run()\n",
    "print(f\"application duration = {app.get_fitness()}\")\n",
    "fig = display_run(data, cluster, width=800, height=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burst Buffer Saturation\n",
    " - will choose bb_size < 5GB (max used size)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# registering Ephemeral Tier\n",
    "bb = EphemeralTier(env, name=\"BB\", persistent_tier=hdd_tier,\n",
    "                        bandwidth=nvram_bandwidth, capacity=4.5e9)\n",
    "\n",
    "# Define the cluster with 1 persistent and 1 ephemeral\n",
    "cluster = Cluster(env, tiers=[hdd_tier], ephemeral_tier=bb)\n",
    "# logger\n",
    "# sim env an data\n",
    "data = simpy.Store(env)\n",
    "logger.remove()\n",
    "# Simple app: read 1GB -> compute 10s -> write 5GB\n",
    "compute = [0,  10]\n",
    "read = [1e9, 0]\n",
    "write = [0, 5e9]\n",
    "placement = [0, 0]\n",
    "use_bb = [False, True] # enabling ephemeral tier for second dataset\n",
    "app = Application(env, compute=compute, read=read, write=write, data=data)\n",
    "env.process(app.run(cluster, placement=placement, use_bb=use_bb))\n",
    "env.run()\n",
    "print(f\"application duration = {app.get_fitness()}\")\n",
    "fig = display_run(data, cluster, width=800, height=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- eviction occurs\n",
    "- buffer saturation should be avoided:\n",
    "  - only newly copied data to lower tier diminishes the amount of dirty data\n",
    "  - we can only evict clean data\n",
    "  - in terms of simulations, it shorten the time interval and the loop become extremly slow (~inf)\n",
    "- the focus is not on studying what happens in saturation mode, but to size relevantly the BB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing BB Size (flavor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "from loguru import logger\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os\n",
    "from itertools import chain\n",
    "from cluster_simulator.cluster import Cluster, Tier, EphemeralTier, bandwidth_share_model, compute_share_model, get_tier, convert_size\n",
    "from cluster_simulator.phase import DelayPhase, ComputePhase, IOPhase\n",
    "from cluster_simulator.application import Application\n",
    "from cluster_simulator.analytics import display_run\n",
    "# imports for surrogate models\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from bbo.optimizer import BBOptimizer\n",
    "# from bbo.optimizer import timeit\n",
    "from bbo.heuristics.surrogate_models.next_parameter_strategies import expected_improvement\n",
    "\n",
    "# imports for genetic algorithms\n",
    "from bbo.heuristics.genetic_algorithm.selections import tournament_pick\n",
    "from bbo.heuristics.genetic_algorithm.crossover import double_point_crossover\n",
    "from bbo.heuristics.genetic_algorithm.mutations import mutate_chromosome_to_neighbor\n",
    "from loguru import logger\n",
    "from cluster_simulator.ephemeral_placement import ClusterBlackBox\n",
    "logger.remove()\n",
    "cbb = ClusterBlackBox()\n",
    "PARAMETER_SPACE = cbb.parameter_space\n",
    "# combinations are self.n_tiers ** sum(self.ios) + 2**sum(self.ios)\n",
    "NBR_ITERATION = 1  # cbb.n_tiers ** sum(cbb.ios)\n",
    "\n",
    "np.random.seed(5)\n",
    "bbopt = BBOptimizer(black_box=cbb,\n",
    "                    heuristic=\"surrogate_model\",\n",
    "                    max_iteration=NBR_ITERATION,\n",
    "                    initial_sample_size=2,\n",
    "                    parameter_space=PARAMETER_SPACE,\n",
    "                    next_parameter_strategy=expected_improvement,\n",
    "                    regression_model=GaussianProcessRegressor)\n",
    "start_time = time.time()\n",
    "bbopt.optimize()\n",
    "print(\"-----------------\")\n",
    "print(f\"Total number of iterations : {NBR_ITERATION}\")\n",
    "print(f\"{(time.time() - start_time)} seconds spent for finding solution\")\n",
    "print(\"-----------------\")\n",
    "bbopt.summarize()\n",
    "print(f\"Fitness history : {bbopt.history['fitness']}\")\n",
    "#cbb.save_experiment(filename = \"flavor_optim\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "!pip3 install pickle5\n",
    "import pickle5 as pickle5\n",
    "\n",
    "pathfile = os.path.join(os.getcwd(), \"flavor_optim\")\n",
    "df = pd.read_pickle(pathfile)\n",
    "df.head(2)\n",
    "#list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Workflow duration Vs BB Size : efficient frontier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "colors = px.colors.qualitative.Plotly\n",
    "fig = go.Figure()\n",
    "fig.add_traces(go.Scatter(x=df['BB_size'], y = df['Fitness'], \n",
    "                          text = [\"trial_index=\" + str(i) for i in list(df.index)],\n",
    "                          mode = 'markers', line=dict(color=colors[0])))\n",
    "fig.update_xaxes(title_text='Size of BB in bytes (B = 1e9 = GB)')\n",
    "fig.update_yaxes(title_text='Workflow duration in seconds')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- each point is a placement configuration:\n",
    "  - for each dataset:\n",
    "    - the tier where it should be placed\n",
    "    - the use or not of the BB to prefetch/buffer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate the number of trial\n",
    "cbb.display_placement(df.loc[29][\"Param\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient frontier / Pareto frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cluster_simulator.utils import convex_hull\n",
    "points = []\n",
    "for (xi, yi) in zip(df['BB_size'].tolist(), (df['Fitness']).tolist()):\n",
    "    points.append((xi,yi))\n",
    "lower = convex_hull(points)\n",
    "fig.add_traces(go.Scatter(x=np.array([low[0] for low in lower]),\n",
    "                            y=np.array([low[1] for low in lower])))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommandation are elements from efficient/pareto frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_trials = [29, 31, 4, 6, 129]\n",
    "df.loc[rec_trials][df.columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display individual points (placement recommandation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = cbb.display_placement(placement=bbopt.best_parameters_in_grid)\n",
    "fig1.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c87beb4c7de1fcbf6155f8da331fc04a584374d4c389d75c2ece6a4f03553c96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
